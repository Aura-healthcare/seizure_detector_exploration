{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from matplotlib import pyplot\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0-rc1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import  OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, recall_score, precision_score,classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.tree import DecisionTreeClassifier,export_graphviz\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des données et nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import des données par un fichier CSV déjà cleané\n",
    "df_swt = pd.read_csv(\"./swt_v2_cleaned.csv\").drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_kept = [8544,9839,10418]  ### à ce stade de l'étude, on avait décidé d'effectuer le \"feature selection sur un groupe réduit de patient \"## 9578 ##9104 #11077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtrage sur le(s) patient(s)\n",
    "df_swt=df_swt[df_swt['Patient'].isin(patient_kept)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#suppression des lignes où le label est vide\n",
    "df_swt.dropna(subset=['label'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remplacement des valeurs de label par 1 si c'est différent de 0\n",
    "df_swt['label']= df_swt['label'].apply(lambda x: 0 if (x==0) else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remplacement des valeurs \"inf\" par Nan\n",
    "df_swt = df_swt.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplacement des valeurs \"Nan\" par la moyenne de l'examen\n",
    "\n",
    "df_swt2 = df_swt.groupby(df_swt['cle_exam']).transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on remet la clé qui a disparu au moment du groupby\n",
    "df_swt2['cle_exam'] = df_swt['cle_exam'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporalisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition d'une fonction pour transformer les series temporelles:\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('%s(t-%d)' % (j, i)) for j in df.columns]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('%s(t)' % (j)) for j in df.columns]\n",
    "        else:\n",
    "            names += [('%s(t+%d)' % (j, i)) for j in df.columns]\n",
    "\t# put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg = agg.iloc[n_in:,]\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition d'une variable qui indique le nombre de périodes que nous allons prendre en compte\n",
    "nb_period = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation d'un dataframe où les series sont temporalisée examen par examen\n",
    "df_swt_temp = pd.DataFrame()\n",
    "\n",
    "for i in df_swt.cle_exam.unique():\n",
    "    df_swt_temp = pd.concat([df_swt_temp,series_to_supervised(df_swt2[df_swt2['cle_exam']== i],nb_period,1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning des colonnes du data set après avoir appliqué la temporalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Liste des dropped_columns/ features avec toutes les variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_columns=['interval_index','Dossier Patient','exam_duration','Pan_vs_SWT','SWT_vs_XQRS',\n",
    "                 'interval_start_time','max_duration','mean_nni%','csi%','hf%']\n",
    "\n",
    "features_non_temp =['cle_exam']\n",
    "\n",
    "numerical_feat = ['mean_nni','sdnn','sdsd','nni_50','pnni_50','nni_20','pnni_20','rmssd',\n",
    "                  'median_nni','range_nni','cvsd','cvnni','mean_hr','max_hr','min_hr','std_hr',\n",
    "                  'lf','hf','vlf','lf_hf_ratio',\n",
    "                  'csi','cvi','Modified_csi','sd1','sd2','ratio_sd2_sd1','sampen']\n",
    "\n",
    "categorical_feat = ['Patient']\n",
    "features_temp = numerical_feat+categorical_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition de la liste des colonnes à dropper (dynamique en fonction du nombre de période)\n",
    "dropped_columns_temp = [s+ \"(t-\"+str(j)+\")\" for s in dropped_columns for j in range(1,nb_period+1)]\n",
    "dropped_columns_temp += [s+ \"(t)\" for s in dropped_columns]\n",
    "#dropped_columns_temp += [\"Patient(t-\"+str(j)+\")\" for j in range(1,nb_period+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_swt_temp =df_swt_temp.drop(dropped_columns_temp,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération des X et Y, puis séparation en Train et Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constitution de la liste des features qui rajoute les (t-n)\n",
    "\n",
    "features_list = ['%s(t-%d)' % (i,j) for i in features_temp for j in range(1,nb_period+1)]\n",
    "features_list +=  ['%s(t)' % i for i in features_temp]\n",
    "features_list +=  ['%s(t)' % i for i in features_non_temp]\n",
    "features_list = sorted(features_list)\n",
    "target_variable = \"label(t)\"\n",
    "\n",
    "X = df_swt_temp.loc[:,features_list]\n",
    "Y = df_swt_temp.loc[:,target_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split test/train\n",
    "\n",
    "X_train, X_test,Y_train, Y_test = train_test_split(X,Y,test_size = 0.2, random_state =42, stratify = Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb exams sur le train:  107\n",
      "nb exams sur le test:  107\n",
      "nb lignes sur le train:  5476\n",
      "nb lignes sur le test:  1370\n"
     ]
    }
   ],
   "source": [
    "# calculate basic figures to share ours results\n",
    "print(\"nb exams sur le train: \",X_train['cle_exam(t)'].unique().shape[0])\n",
    "print(\"nb exams sur le test: \",X_test['cle_exam(t)'].unique().shape[0])\n",
    "print(\"nb lignes sur le train: \",X_train.shape[0])\n",
    "print(\"nb lignes sur le test: \",X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop \"cle_exam\" (je la gardais pour pouvoir calculer le nb d'exams et de lignes juste avant)\n",
    "cle_exam_list = ['cle_exam(t)']\n",
    "\n",
    "X_train = X_train.drop(cle_exam_list,axis=1)\n",
    "X_test = X_test.drop(cle_exam_list,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement en boucle d'un Decision Tree en testant toutes les combinaisons de features à 2, 3 ou 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "# definition d'une liste de toutes les combinaisons de  N features\n",
    "from random import sample\n",
    "\n",
    "# on règle ici la taille des listes. plus le chiffre est important, plus c'est long\n",
    "N = 6\n",
    "list_permuts =[]\n",
    "i = 0\n",
    "for subset in itertools.combinations(numerical_feat, N):\n",
    "    list_permuts.append(subset)\n",
    "\n",
    "#on limite le nombre de combinaison à tester à 5000\n",
    "\n",
    "if len(list_permuts)>5000:\n",
    "    list_permuts = sample(list_permuts,5000)\n",
    "\n",
    "print(len(list_permuts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "###définition d'une fonction qui gère l'encoding de façon un peu plus dynamique\n",
    "\n",
    "def my_normalisation_ecoding(X_train, X_test, numeric_feat, categoric_feat, nb_t):\n",
    "\n",
    "    # Normalization\n",
    "    numeric_transformer = StandardScaler()\n",
    "    # OHE / dummyfication\n",
    "    categorical_indices =[X_train.columns.get_loc('%s(t-%d)' %  (i,j)) for i in categoric_feat for j in range(1,nb_t+1)]\n",
    "    categorical_indices += [X_train.columns.get_loc('%s(t)' %  i) for i in categoric_feat]\n",
    "    categorical_indices = sorted(categorical_indices)\n",
    "\n",
    "    numeric_indices =[X_train.columns.get_loc('%s(t-%d)' %  (i,j)) for i in numeric_feat for j in range(1,nb_t+1)]\n",
    "    numeric_indices += [X_train.columns.get_loc('%s(t)' %  i) for i in numeric_feat]\n",
    "    numeric_indices = sorted(numeric_indices)\n",
    "\n",
    "\n",
    "    categorical_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "    featureencoder = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_indices),    \n",
    "            ('num', numeric_transformer, numeric_indices)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    X_train_fit = featureencoder.fit_transform(X_train)\n",
    "    X_test_fit = featureencoder.transform(X_test)\n",
    "    return X_train_fit, X_test_fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [35:44<00:00,  2.33it/s]\n"
     ]
    }
   ],
   "source": [
    "results_features = pd.DataFrame()\n",
    "\n",
    "# Boucle d'entrainement sur toutes les combinaisons de features\n",
    "\n",
    "for list_i in tqdm(list_permuts):\n",
    "    list_i_full = list(list_i) + categorical_feat\n",
    "    features_list = ['%s(t-%d)' % (i,j) for i in list_i_full for j in range(1,nb_period+1)]\n",
    "    features_list +=  ['%s(t)' % i for i in list_i_full]\n",
    "    features_list = sorted(features_list)\n",
    "    \n",
    "    X = df_swt_temp.loc[:,features_list]\n",
    "    Y = df_swt_temp.loc[:,target_variable]\n",
    "    \n",
    "    X_train, X_test,Y_train, Y_test = train_test_split(X,Y,test_size = 0.2, random_state =42, stratify = Y)\n",
    "\n",
    "    X_train_fit,X_test_fit = my_normalisation_ecoding(X_train, X_test,list_i, categorical_feat, nb_period)\n",
    "    \n",
    "    #classifier = XGBClassifier(n_jobs=8,verbosity=0,learning_rate=0.5,max_depth=10,n_estimators=500)\n",
    "    classifier = DecisionTreeClassifier()\n",
    "    classifier.fit(X_train_fit,Y_train)\n",
    "    Y_train_pred = classifier.predict(X_train_fit)\n",
    "    Y_test_pred = classifier.predict(X_test_fit)\n",
    "    # on met tous les résultats dans un DataFrame \"results_features\"\n",
    "    results_features = results_features.append(pd.DataFrame({\"iteration\":[list_i],\n",
    "                   \"confustion matrix train\": [confusion_matrix(Y_train, Y_train_pred)],\n",
    "                   \"confustion matrix test\": [confusion_matrix(Y_test, Y_test_pred)],\n",
    "                   \"recall score train\": [recall_score(Y_train,Y_train_pred)],\n",
    "                   \"recall score test\": [recall_score(Y_test,Y_test_pred)],\n",
    "                   \"f1_score train\": [f1_score(Y_train,Y_train_pred)],\n",
    "                   \"f1_score test\": [f1_score(Y_test,Y_test_pred)],\n",
    "                   }),ignore_index=True\n",
    "                            )\n",
    "#on trie par F1 score descendant\n",
    "results_features = results_features.sort_values(by='f1_score test',ascending=False)\n",
    "#petite sauvegarde\n",
    "results_features.to_csv('./results_{}features.csv'.format(N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Résultats: meilleurs combinaisons de features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boucle pour compter le nombre de fois où une feature apparait (sur les 30 meilleurs F1 score puisque c'est trié par f1 score decroissant)\n",
    "count_features = []\n",
    "for i in results_features.head(30)['iteration']:\n",
    "    for j in range(0,len(i)):\n",
    "        count_features.append(i[j])\n",
    "\n",
    "Counter(count_features).most_common()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
